{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: 'matplotlib,'\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib, pandas, openpyxl, scikit-learn, plotly, --upgrade nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Encoded_Data_for_Model_Training.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "encoded_scaled = scaler.fit_transform(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "principalComponents = pca.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pc = pca.components_[1, :]\n",
    "\n",
    "# Plot first_pc as an arrow, starting at mean\n",
    "plt.arrow(mean[0], mean[1], first_pc[0], first_pc[1], color='red', width=0.01)\n",
    "\n",
    "# Keep axes on the same scale\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(encoded_scaled)\n",
    "# Elbow method to determine optinal number of components\n",
    "# Proportion of variance explained criterion\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot criterion for selecting principal components\n",
    "covar_matrix = PCA(n_components = len(encoded_data.columns))\n",
    "covar_matrix.fit(encoded_scaled)\n",
    "\n",
    "# visualizing the eigenvalues obtained from performing Principal Component Analysis (PCA) on the dataset and identifying significant components based on a threshold (in this case, eigenvalues greater than 1) \n",
    "# Once a principal component's eigenvalue is on or below the threshold, it suggests that the corresponding principal component may not explain a significant amount of variance in the data\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6)) \n",
    "\n",
    "plt.ylabel('Eigenvalues')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Eigenvalues')\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "# plt.xticks(range(len(covar_matrix.explained_variance_)))\n",
    "for x_position in range(len(covar_matrix.explained_variance_)):\n",
    "    plt.scatter(x_position, covar_matrix.explained_variance_[x_position])\n",
    "\n",
    "plt.axhline(y=1, color='gray', linestyle='--')\n",
    "plt.plot(covar_matrix.explained_variance_, color='blue', marker='o', linestyle='--', linewidth=2, markersize=12, markerfacecolor='white', markeredgecolor='black')\n",
    "\n",
    "plt.grid(True, linestyle='-', alpha=0.6)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the explained variance ratio of each principal component obtained from PCA-variance drop off point is 3\n",
    "features = range(pca.n_components_)\n",
    "plt.bar(features, pca.explained_variance_ratio_, color='black')\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.xticks(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Implementation w the optimal # of components\n",
    "pca = PCA(n_components = 4)\n",
    "pca.fit(encoded_scaled)\n",
    "pca_features = pca.transform(encoded_data)\n",
    "print(pca_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(pca_features)\n",
    "    wcss.append(kmeans.inertia_)  # Inertia is the WCSS\n",
    "\n",
    "# Plotting the elbow curve\n",
    "plt.plot(range(1, 11), wcss, marker='o')\n",
    "plt.title('Elbow Method for selection of optimal \"K\" clusters')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('WCSS (Within-Cluster Sum of Squares)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of cluster numbers (K) to evaluate\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1, but in this example, all lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette plots of individual clusters\n",
    "    ax1.set_ylim([0, len(pca_features) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the KMeans object and fit it to the data\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(pca_features)\n",
    "\n",
    "    # Compute the silhouette score for the current clustering\n",
    "    silhouette_avg = silhouette_score(pca_features, cluster_labels)\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette score is: {silhouette_avg}\")\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(pca_features, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to the current cluster\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        # Sort the silhouette scores\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        # Fill the silhouette plot\n",
    "        color = plt.cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plot with cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for the next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"Silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"Silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for the average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([])  # Clear the y-axis labels\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = plt.cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(pca_features[:, 0], pca_features[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = kmeans.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"Visualization of clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KMeans without PCA and no standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_standard = KMeans(n_clusters=3, random_state=1234, n_init=10)\n",
    "kmeans_standard.fit(encoded_data)\n",
    "\n",
    "centroids = kmeans_standard.cluster_centers_\n",
    "\n",
    "cluster_labels = kmeans_standard.labels_\n",
    "\n",
    "# Get the distance between each point and the nearest centroid\n",
    "distances = kmeans_standard.transform(encoded_data)\n",
    "\n",
    "# Get the inertia (sum of squared distances to nearest centroid)\n",
    "inertia = kmeans.inertia_\n",
    "# print(labels)\n",
    "# print(inertia)\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(encoded_data.iloc[:, 0], encoded_data.iloc[:, 1], c=cluster_labels, cmap='viridis', alpha=0.5, label='Data Points')\n",
    "\n",
    "# Plot centroids\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], marker='D', s=50, c='red', label='Centroids')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('KMeans Clustering with Centroids')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(pca_features)\n",
    "# Scatter plot of data points\n",
    "plt.scatter(pca_features[:, 0], pca_features[:, 1], c=cluster_labels, alpha=0.5, label='Data Points')\n",
    "\n",
    "# Scatter plot of centroids\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='D', s=50, c='red', label='Centroids')\n",
    "\n",
    "# Show the plot\n",
    "plt.legend()\n",
    "plt.title('K-Means Clustering with Centroids')\n",
    "plt.xlabel('PCA Feature 1')\n",
    "plt.ylabel('PCA Feature 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image will be displayed in the readme file as well\n",
    "import plotly.express as px\n",
    "\n",
    "# Scatter plot of data points\n",
    "fig = px.scatter(x=pca_features[:, 0], y=pca_features[:, 1], color=cluster_labels, opacity=0.5, labels={'x': 'PCA Feature 1', 'y': 'PCA Feature 2'}, title='K-Means Clustering with Centroids', template='plotly_white')\n",
    "\n",
    "# Scatter plot of centroids\n",
    "fig.add_scatter(x=kmeans.cluster_centers_[:, 0], y=kmeans.cluster_centers_[:, 1], mode='markers', marker=dict(symbol='diamond', size=10, color='red'), name='Centroids')\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
